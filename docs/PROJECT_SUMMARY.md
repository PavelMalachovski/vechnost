# Project Summary: Tribute Webhook Handler

## üì¶ Complete FastAPI + SQLAlchemy 2 + Alembic Project

A production-ready webhook handler for Tribute payment events with:
- ‚úÖ **Async FastAPI** with proper signature verification
- ‚úÖ **SQLAlchemy 2.0** with async support
- ‚úÖ **Alembic** migrations configured for SQLite (batch mode)
- ‚úÖ **Idempotency** via SHA256 body hashing
- ‚úÖ **Clean architecture** - easy to extend and test

---

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Package marker
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # FastAPI app + webhook handlers
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Settings from .env
‚îÇ   ‚îú‚îÄ‚îÄ database.py           # Async engine + sessions
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # SQLAlchemy 2.0 models
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Pydantic request/response
‚îÇ   ‚îî‚îÄ‚îÄ crud.py               # Database operations
‚îÇ
‚îú‚îÄ‚îÄ alembic/
‚îÇ   ‚îú‚îÄ‚îÄ env.py                # Migration environment (render_as_batch=True)
‚îÇ   ‚îú‚îÄ‚îÄ script.py.mako        # Migration template
‚îÇ   ‚îî‚îÄ‚îÄ versions/             # Migration files go here
‚îÇ
‚îú‚îÄ‚îÄ alembic.ini               # Alembic configuration
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ .env                      # Environment variables (you edit this)
‚îú‚îÄ‚îÄ .gitignore                # Git exclusions
‚îÇ
‚îú‚îÄ‚îÄ README.md                 # Full documentation
‚îú‚îÄ‚îÄ QUICKSTART.md             # 2-minute setup guide
‚îú‚îÄ‚îÄ MIGRATION_GUIDE.md        # Database migration details
‚îú‚îÄ‚îÄ docker-compose.yml        # Docker setup (optional)
‚îú‚îÄ‚îÄ Dockerfile                # Docker image (optional)
‚îî‚îÄ‚îÄ test_webhook.sh           # Webhook testing script
```

---

## üöÄ Quick Start (3 Commands)

```bash
# 1. Install
pip install -r requirements.txt

# 2. Initialize database
alembic revision --autogenerate -m "initial tables"
alembic upgrade head

# 3. Run
uvicorn app.main:app --reload
```

**Done!** API running at http://localhost:8000

---

## üîê Security Features

### 1. **HMAC-SHA256 Signature Verification**
```python
def verify_signature(raw_body: bytes, signature: str) -> bool:
    expected = hmac.new(TRIBUTE_API_KEY.encode(), raw_body, hashlib.sha256).hexdigest()
    return hmac.compare_digest(expected, signature)
```

- Verifies `trbt-signature` header
- Uses constant-time comparison
- Returns 401 on invalid signature

### 2. **Idempotency Protection**
```python
body_sha256 = hashlib.sha256(raw_body).hexdigest()
# Stored in payments.body_sha256 (unique constraint)
```

- Detects duplicate webhooks
- Returns `{"ok": true, "dup": true}` for duplicates
- Prevents double-processing

---

## üóÑÔ∏è Database Models

### **Users**
- Telegram user data (telegram_user_id unique)
- Auto-upserted on every webhook

### **Products**
- Available products/plans
- Links for Telegram & web payments

### **Payments**
- All payment transactions
- Stores raw webhook body (JSON)
- SHA256 hash for idempotency

### **Subscriptions**
- User subscription status
- Period, status, expires_at
- Unique per (user_id, subscription_id)

### **WebhookEvents**
- Audit log of all webhooks
- Tracks processing status & errors

---

## üì° Webhook API

### **Endpoint**
```
POST /webhook/tribute
Content-Type: application/json
trbt-signature: <HMAC-SHA256>
```

### **Events Handled**

1. **`new_digital_product`** - One-time purchase
   ```json
   {
     "event_name": "new_digital_product",
     "telegram_user_id": 123456789,
     "username": "testuser",
     "amount": 299,
     "currency": "RUB",
     "product_id": 1
   }
   ```

2. **`new_subscription`** - Recurring subscription
   ```json
   {
     "event_name": "new_subscription",
     "telegram_user_id": 123456789,
     "subscription_id": 456,
     "period": "monthly",
     "amount": 299,
     "expires_at": "2025-02-12T00:00:00Z"
   }
   ```

3. **`cancelled_subscription`** - Cancellation
   ```json
   {
     "event_name": "cancelled_subscription",
     "telegram_user_id": 123456789,
     "subscription_id": 456
   }
   ```

### **Responses**

| Code | Body | Meaning |
|------|------|---------|
| 200 | `{"ok": true}` | Success |
| 200 | `{"ok": true, "dup": true}` | Duplicate (idempotent) |
| 401 | `{"detail": "Invalid signature"}` | Bad signature |
| 400 | `{"detail": "..."}` | Malformed request |
| 500 | `{"detail": "..."}` | Server error |

---

## üß™ Testing

### **Test Script**
```bash
./test_webhook.sh
```

Tests:
- ‚úÖ new_digital_product event
- ‚úÖ new_subscription event
- ‚úÖ cancelled_subscription event
- ‚úÖ Duplicate detection (idempotency)
- ‚úÖ Invalid signature rejection (401)

### **Manual Test**
```bash
API_KEY="your_key"
BODY='{"event_name":"new_digital_product","telegram_user_id":123,"amount":100}'
SIG=$(echo -n "$BODY" | openssl dgst -sha256 -hmac "$API_KEY" | awk '{print $2}')

curl -X POST http://localhost:8000/webhook/tribute \
  -H "Content-Type: application/json" \
  -H "trbt-signature: $SIG" \
  -d "$BODY"
```

---

## üêò Switching to PostgreSQL

The SAME migrations work for both databases!

```bash
# 1. Install driver
pip install psycopg2-binary asyncpg

# 2. Update .env
DATABASE_URL=postgresql+asyncpg://user:pass@localhost/tribute_db

# 3. Run migrations (identical command!)
alembic upgrade head
```

That's it! The `render_as_batch=True` in `alembic/env.py` makes it work.

---

## üîß Key Configuration

### **Alembic SQLite Batch Mode**
```python
# alembic/env.py
context.configure(
    connection=connection,
    target_metadata=target_metadata,
    render_as_batch=True,  # ‚Üê Makes migrations work on SQLite
)
```

This enables:
- Adding columns with constraints
- Renaming columns
- Adding foreign keys
- Modifying unique constraints

### **Environment Variables**
```bash
DATABASE_URL=sqlite+aiosqlite:///./tribute.db  # SQLite (default)
# DATABASE_URL=postgresql+asyncpg://...        # Postgres
TRIBUTE_API_KEY=your_key_here                  # Required!
DEBUG=false
```

---

## üì¶ Dependencies

### **Core**
- `fastapi` - Async web framework
- `uvicorn` - ASGI server
- `pydantic` - Data validation
- `sqlalchemy[asyncio]` - Async ORM
- `aiosqlite` - SQLite async driver
- `alembic` - Database migrations

### **For Postgres** (install later)
- `psycopg2-binary` - Postgres sync driver
- `asyncpg` - Postgres async driver

---

## üéØ What Makes This Production-Ready

1. **‚úÖ Async Everything** - FastAPI + SQLAlchemy async
2. **‚úÖ Proper Security** - HMAC signature verification
3. **‚úÖ Idempotency** - SHA256 deduplication
4. **‚úÖ Error Handling** - Graceful failures, error logging
5. **‚úÖ Database Migrations** - Alembic with batch mode
6. **‚úÖ Type Safety** - Pydantic schemas, SQLAlchemy 2.0 typed models
7. **‚úÖ Clean Architecture** - Separated concerns (CRUD, models, schemas)
8. **‚úÖ Docker Ready** - Dockerfile + docker-compose.yml
9. **‚úÖ Testing Tools** - test_webhook.sh script
10. **‚úÖ Documentation** - README, QUICKSTART, MIGRATION_GUIDE

---

## üìñ Documentation Files

- **README.md** - Complete guide (setup, API, deployment)
- **QUICKSTART.md** - 2-minute start (install ‚Üí run ‚Üí test)
- **MIGRATION_GUIDE.md** - Database migrations & Postgres switch
- **PROJECT_SUMMARY.md** - This file (overview)

---

## üö¢ Deployment Options

### **Option 1: Docker**
```bash
docker-compose up -d
```

### **Option 2: Systemd**
```bash
# Create systemd service
sudo nano /etc/systemd/system/tribute-webhook.service

[Unit]
Description=Tribute Webhook Handler
After=network.target

[Service]
User=www-data
WorkingDirectory=/var/www/tribute-webhook
Environment="PATH=/var/www/tribute-webhook/venv/bin"
ExecStart=/var/www/tribute-webhook/venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

### **Option 3: Gunicorn**
```bash
gunicorn app.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000
```

---

## üêõ Troubleshooting

### **"Table already exists"**
```bash
alembic stamp head  # Mark current DB state
```

### **"Invalid signature"**
- Check `TRIBUTE_API_KEY` is correct
- Verify raw body is used (not parsed JSON)
- Check signature is hex lowercase

### **"Cannot add NOT NULL column" (SQLite)**
Shouldn't happen with `render_as_batch=True`, but if it does:
```python
# Make column nullable first
batch_op.add_column(sa.Column('field', sa.String(), nullable=True))
# Then add data migration, then make NOT NULL in another migration
```

---

## ‚ú® Next Steps

1. **Add your Tribute API key** to `.env`
2. **Test webhooks** with `test_webhook.sh`
3. **Deploy** to your server
4. **Configure Tribute** to send webhooks to your endpoint
5. **Monitor** via `/health` endpoint
6. **Switch to Postgres** when ready for production

---

## üìû Support

- Tribute API issues ‚Üí Contact Tribute support
- Code issues ‚Üí Check README.md and MIGRATION_GUIDE.md
- Questions ‚Üí Review inline code comments

---

## üéâ You're Ready!

This is a complete, production-ready webhook handler. Everything is configured and tested. Just add your API key and deploy!

**Last updated:** 2025-01-12

